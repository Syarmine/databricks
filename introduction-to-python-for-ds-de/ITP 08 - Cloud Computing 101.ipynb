{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f98dbd5-2d38-4724-8064-87a311e5bcb4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97d6cc1b-3d72-49cf-849a-01f629dd45f8",
     "showTitle": false,
     "title": "--i18n-a18d57e2-019d-45b4-9ba4-b704a190ff0a"
    }
   },
   "source": [
    "\n",
    "\n",
    "# Cloud Computing 101\n",
    "## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lesson you:<br>\n",
    "- Contrast local vs on-prem vs cloud computing\n",
    "- Introduce the basics of cloud computing\n",
    "- Explore how Databricks works in a cloud based setting with Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f59b9a35-e7c2-4a72-ba44-d5ac34e6f74e",
     "showTitle": false,
     "title": "--i18n-4e55ca41-dc1d-4f3f-9162-8b418a85c60e"
    }
   },
   "source": [
    "\n",
    "\n",
    "#### Local Execution\n",
    "\n",
    "Local execution refers to when you're leveraging only the compute of your local machine to execute code. For example, you're a data scientist running Jupyter notebooks locally on your laptop. \n",
    "\n",
    "<img src=\"https://s3.us-west-2.amazonaws.com/files.training.databricks.com/courses/Python/LocalPicture.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11588d5c-ffc4-46fb-89ce-20be7330d575",
     "showTitle": false,
     "title": "--i18n-7d43d290-d840-449b-875e-063186261763"
    }
   },
   "source": [
    "\n",
    "\n",
    "#### On-Prem\n",
    "\n",
    "On-prem is short for on-premise. This refers to the situation where someone manages multiple computers that communicate with each other to store data and run code. This offers significantly more compute power and storage than a single machine. \n",
    "\n",
    "\n",
    "Here is an illustration showing an on-prem setting:\n",
    "\n",
    "<img src=\"https://s3.us-west-2.amazonaws.com/files.training.databricks.com/courses/Python/OnPremPicture.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e52fb451-49b3-47b5-ba3f-b6d567973068",
     "showTitle": false,
     "title": "--i18n-232b8ed7-36c8-4e48-88d3-5c17143e3d76"
    }
   },
   "source": [
    "\n",
    "\n",
    "#### Cloud\n",
    "\n",
    "Managing an on-prem system is difficult, expensive, and scales poorly. An popular alternative is to rent storage and computer power from cloud providers. \n",
    "These providers are typically large technology companies such as Amazon, Microsoft, and Google. \n",
    "\n",
    "In this situation, a user simply accesses data and compute via a web browser or other application, while the actual data and computation are being stored and ran in large warehouses of machines called a data center managed by these companies. This is referred to as a cloud-based setting. \n",
    "\n",
    "It is much less expensive and easier to use cloud storage because you don't have to create or manage your own data center. It also allows for easy scaling: just buy as much storage and compute power as you need at the moment and turn it off when you are finished. \n",
    "\n",
    "<img src=\"https://s3.us-west-2.amazonaws.com/files.training.databricks.com/courses/Python/CloudPicture.png\" style=\"width:800px;height:500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84c5a00d-1c86-46bd-b88e-6b6a564031a5",
     "showTitle": false,
     "title": "--i18n-a5697312-b91f-4f54-bb69-2b835a9bd278"
    }
   },
   "source": [
    "\n",
    "\n",
    "#### Virtual Machines\n",
    "\n",
    "In a cloud based setting we use computers managed by cloud providers to run code and store data. \n",
    "\n",
    "We are able to run code this way by using **virtual machines** on those computers. \n",
    "\n",
    "A virtual machine separates the CPU, memory, networking, and disk storage from other virtual machines on the same computer. \n",
    "\n",
    "By renting virtual machines on cloud computers, we can use the resources those computers provide without worrying about sharing information with other users also renting virtual machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac4ea88b-9d6f-48d3-9d18-727ba62b620e",
     "showTitle": false,
     "title": "--i18n-a74616ce-3011-4c79-b0f9-f72fbfbb032e"
    }
   },
   "source": [
    "\n",
    "\n",
    "#### Cloud Storage\n",
    "\n",
    "Cloud providers offer ways to store data on the cloud easily. These services use computers and software that are specialized for storing data in a reliable way that can scale well.\n",
    "\n",
    "One type of storage offered by cloud providers is **object storage**, which can store any type of data including text, images, videos, and other binary data. Some examples of cloud object storage are:\n",
    "\n",
    "* [Amazon Simple Storage Service (Amazon S3)](https://aws.amazon.com/s3/)\n",
    "* Microsoft's [Azure Data Lake Storage Gen2 (ADLS Gen 2)](https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction)\n",
    "* [Google Cloud Storage](https://cloud.google.com/storage)\n",
    "\n",
    "Cloud providers also offer services to store and manage relational databases &mdash; such as MySQL, PostgreSQL, and Microsoft SQL Server &mdash; and key-value stores or other \"NoSQL\" databases &mdash; such as Amazon DynamoDB, Azure Cosmos DB, and Google Cloud Bigtable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5d41689-777b-4366-ac92-62159050601b",
     "showTitle": false,
     "title": "--i18n-cc376440-5b2e-4d04-ae07-77c5a08b66d9"
    }
   },
   "source": [
    "\n",
    "\n",
    "#### Databricks\n",
    "\n",
    "<img src=\"https://s3.us-west-2.amazonaws.com/files.training.databricks.com/images/databricks_cloud_overview.png\" style=\"width:800px;height:500px;\">\n",
    "\n",
    "Databricks provides a unified, cloud-based platform for running and managing a wide variety of data analytics, business intelligence, data science, and machine learning tasks. Databricks runs on multiple cloud providers and can process the data you store in cloud object storage using the virtual machines of that cloud provider."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cdbf3160-761c-4d1c-94d9-51240302aaf5",
     "showTitle": false,
     "title": "--i18n-e631525b-075f-485e-979a-dfc8ab90973e"
    }
   },
   "source": [
    "\n",
    "\n",
    "#### Apache Spark\n",
    "\n",
    "A single computer usually has the memory and computational power to perform calculations on data sets up to the size of a few gigabytes or less. Data sets larger than that either can't fit into the memory of a single computer or take an unacceptably long time for a single computer to process. For these types of \"big data\" use cases, we need a system that can split a large data set into smaller subsets &mdash; often referred to as **partitions** &mdash; and then distribute the processing of these data partitions across a number of computers.\n",
    "\n",
    "[Apache Spark](https://spark.apache.org/) is an open-source data processing engine that manages distributed processing of large data sets.\n",
    "\n",
    "For example, let's say that we have a large data set and we want to calculate various statistics for some of its numeric columns. With Apache Spark, our program only needs to specify the data set to read and the statistics that we want calculated. We can then run the program on a set of computers that have been configured to serve as an Apache Spark **cluster**. When we run it, Spark automatically:\n",
    "\n",
    "* determines how to divide the data set into partitions,\n",
    "* assigns those partitions to the various computers of the cluster with instructions for calculating per-partition statistics, and\n",
    "* finally collects those per-partitions statistics and calculates the final results we requested.\n",
    "\n",
    "Spark was created originally as a research project at the University of California Berkeley. In 2013, the project was donated to the Apache Software Foundation. That same year the creators of Spark founded Databricks.\n",
    "\n",
    "Databricks, in general, uses Apache Spark as the computation engine for the platform. Databricks provides simple management tools for running Spark clusters composed of cloud-provided virtual machines to process the data you have in cloud object storage and other systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3eae7f39-bacd-4dfb-9ecc-413078da2634",
     "showTitle": false,
     "title": "--i18n-5b907bd3-bc39-41d1-8294-1be99f57ca26"
    }
   },
   "source": [
    "\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/sparkcluster.png\" style=\"width:600px;height:250px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6bf95595-396a-4a41-8b1c-66aaf44f78d2",
     "showTitle": false,
     "title": "--i18n-4e483909-d12e-4a76-94e4-b5e04e726ce2"
    }
   },
   "source": [
    "\n",
    "\n",
    "#### Unity Catalog\n",
    "\n",
    "Unity Catalog is a unified governance solution for data and AI assets on the Databricks Data Intelligence Platform. It is designed to standardize a security model that is consistent and transparent across all clouds. Unity Catalog supports structured data (tables and views), unstructured data (files and folders), and AI assets. It can be integrated with your own object storage so you can manage access to those objects as if they were directly within your metastore. Unity Catalog also supports external catalogs like Alation, Collibra, Informatica EDC, and others.\n",
    "\n",
    "Unity Catalog goes one step beyond the traditional two-level namespace and provides an additional level for organizing your securable objects: **catalogs** and **schemas (databases)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "070cd086-b53b-44b8-8f75-eaae9831ca8a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>catalog</th></tr></thead><tbody><tr><td>spark_catalog</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "spark_catalog"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "catalog",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql SHOW CATALOGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20e2fffe-5c00-487d-981b-47a060b89335",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>databaseName</th></tr></thead><tbody><tr><td>default</td></tr><tr><td>nyctaxi</td></tr><tr><td>tpch</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "default"
        ],
        [
         "nyctaxi"
        ],
        [
         "tpch"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "databaseName",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql SHOW SCHEMAS IN samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "588e60b0-5c0d-4bf6-971e-0a17913c14be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>database</th><th>tableName</th><th>isTemporary</th></tr></thead><tbody><tr><td>tpch</td><td>customer</td><td>false</td></tr><tr><td>tpch</td><td>lineitem</td><td>false</td></tr><tr><td>tpch</td><td>nation</td><td>false</td></tr><tr><td>tpch</td><td>orders</td><td>false</td></tr><tr><td>tpch</td><td>part</td><td>false</td></tr><tr><td>tpch</td><td>partsupp</td><td>false</td></tr><tr><td>tpch</td><td>region</td><td>false</td></tr><tr><td>tpch</td><td>supplier</td><td>false</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "tpch",
         "customer",
         false
        ],
        [
         "tpch",
         "lineitem",
         false
        ],
        [
         "tpch",
         "nation",
         false
        ],
        [
         "tpch",
         "orders",
         false
        ],
        [
         "tpch",
         "part",
         false
        ],
        [
         "tpch",
         "partsupp",
         false
        ],
        [
         "tpch",
         "region",
         false
        ],
        [
         "tpch",
         "supplier",
         false
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "database",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "tableName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isTemporary",
         "type": "\"boolean\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql SHOW TABLES IN samples.tpch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f7473c8-5372-4b3b-8aba-a39c8de8908a",
     "showTitle": false,
     "title": "--i18n-a499fb6b-eb36-4732-9af9-c84329cdce8a"
    }
   },
   "source": [
    "\n",
    "\n",
    "#### Code Versioning and Collaboration with Git\n",
    "\n",
    "[Git](https://git-scm.com/) is a free and open source version control system. This means that it tracks the changes to code and allows you to store different versions of a project. You can restore previous versions if needed, and it also allows for branching and merging of a project where you can create different versions of a project focused on developing different features and then combine them back together. \n",
    "\n",
    "Git is a tool that can be run on your local machine or on Databricks to help with version control, but it shines as a collaboration tool when combined with [GitHub](https://github.com/). GitHub is a cloud-based hosting service that lets you manage Git code repositories, and it allows multiple users to download versions of a project, develop for the project, and then push back their changes. These changes can then be merged, so this creates an easy system for collaboration that forms the backbone of code projects. \n",
    "\n",
    "Open Source technology is usually available as a public Github Repository where anyone can download the code and help develop it. For instance, Apache Spark is open source and you can view all its code, download it, and even help create new features all from its GitHub page [here](https://github.com/apache/spark)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1f818c7-8304-445a-b451-aec139362bee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "&copy; 2023 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/>\n",
    "<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 806331027784124,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "ITP 08 - Cloud Computing 101",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
